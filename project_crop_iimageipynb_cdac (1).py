# -*- coding: utf-8 -*-
"""project_cropipynb_cdac.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OvSdQbNFTQuZfqheOXS1SyklI5fbxWTi
"""

!pip install timm

!pip install pytorch-tabnet

import torch
import torchvision
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

# Check if CUDA is available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

import torch
from torchvision import transforms

# Define transformations for training images (including data augmentation)
train_transforms = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(15),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],  # Mean values for ImageNet pretrained models
                         [0.229, 0.224, 0.225])  # Std dev values for ImageNet pretrained models
])

# Define transformations for testing images
test_transforms = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225])
])

"""**Kindly upload the datset in google drive  provide in git to use this code at collab**"""

from google.colab import drive
drive.mount('/content/drive')

from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader

# Set paths for training and testing images
train_dir = "/content/drive/My Drive/Dataset/Train"
test_dir = "/content/drive/My Drive/Dataset/test"

# Load datasets
train_dataset = ImageFolder(root=train_dir, transform=train_transforms)
test_dataset = ImageFolder(root=test_dir, transform=test_transforms)

# Print some information about the datasets
print("Classes in Training Dataset:", train_dataset.classes)
print("Number of training images:", len(train_dataset))
print("Number of test images:", len(test_dataset))

# Create DataLoaders
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)

import matplotlib.pyplot as plt
import numpy as np

# Function to display an image
def imshow(img, title):
    # unnormalize
    img = img.numpy().transpose((1, 2, 0))
    mean = np.array([0.485, 0.456, 0.406])
    std = np.array([0.229, 0.224, 0.225])
    img = std * img + mean
    img = np.clip(img, 0, 1)
    plt.imshow(img)
    plt.title(title)
    plt.axis('off')
    plt.show()

# Get a batch of training data
data_iter = iter(train_loader)
images, labels = next(data_iter)

# Display the first 4 images from the batch
for i in range(4):
    imshow(images[i], title=train_dataset.classes[labels[i]])

# Soil Types dataset (e.g., for additional experiments)
soil_types_dir = '/content/drive/My Drive/Soil types'
soil_types_dataset = ImageFolder(root=soil_types_dir, transform=test_transforms)

print("Soil Types Classes:", soil_types_dataset.classes)
print("Number of images in Soil Types dataset:", len(soil_types_dataset))

import torch
import torch.nn as nn
import torch.optim as optim

class CustomCNN(nn.Module):
    def __init__(self, num_classes):
        super(CustomCNN, self).__init__()
        # Convolutional Block 1
        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)
        self.bn1   = nn.BatchNorm2d(16)
        self.pool  = nn.MaxPool2d(kernel_size=2, stride=2)

        # Convolutional Block 2
        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)
        self.bn2   = nn.BatchNorm2d(32)

        # Convolutional Block 3
        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)
        self.bn3   = nn.BatchNorm2d(64)

        # After three poolings: image size reduces from 224x224 -> 112x112 -> 56x56 -> 28x28
        self.fc1   = nn.Linear(64 * 28 * 28, 256)
        self.dropout = nn.Dropout(0.5)
        self.fc2   = nn.Linear(256, num_classes)

    def forward(self, x):
        x = self.pool(torch.relu(self.bn1(self.conv1(x))))
        x = self.pool(torch.relu(self.bn2(self.conv2(x))))
        x = self.pool(torch.relu(self.bn3(self.conv3(x))))
        # Flatten the tensor for the fully connected layers
        x = x.view(x.size(0), -1)
        x = torch.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.fc2(x)
        return x

# Verify the architecture with the number of classes from the train dataset:
num_classes = len(train_dataset.classes)  # e.g., 4 classes for Alluvial, Black, Clay, Red soils
model_custom = CustomCNN(num_classes=num_classes)
print(model_custom)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model_custom = model_custom.to(device)

# Define the loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model_custom.parameters(), lr=1e-3)

num_epochs = 15  # Adjust number of epochs based on your experimentation

for epoch in range(num_epochs):
    model_custom.train()  # Set model to training mode
    running_loss = 0.0
    correct = 0
    total = 0

    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()  # Clear gradients

        # Forward pass
        outputs = model_custom(images)
        loss = criterion(outputs, labels)

        # Backward pass and update weights
        loss.backward()
        optimizer.step()

        # Accumulate loss and compute accuracy
        running_loss += loss.item() * images.size(0)
        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

    epoch_loss = running_loss / len(train_dataset)
    epoch_acc = 100 * correct / total
    print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%")

model_custom.eval()  # Set model to evaluation mode
correct_test = 0
total_test = 0

with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model_custom(images)
        _, predicted = torch.max(outputs, 1)
        total_test += labels.size(0)
        correct_test += (predicted == labels).sum().item()

test_accuracy = 100 * correct_test / total_test
print(f"Test Accuracy: {test_accuracy:.2f}%")

print(f"Test Accuracy: {test_accuracy:.2f}%")

# üîΩ Save model
torch.save(model_custom.state_dict(), '/content/drive/MyDrive/model_custom.pth')

train_dataset.classes

import os
print("Files in Google Drive:")
print(os.listdir("/content/drive/MyDrive"))

"""for soil classifaction"""

from torchvision.datasets import ImageFolder
soil_train_dataset = ImageFolder(root=train_dir, transform=train_transforms)

import torch
from torchvision import transforms
from PIL import Image
import os

# Set device (same as in training)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Set model to evaluation mode
model_custom.eval()
model_custom.to(device)

# Define the transformation (must match training)
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.5]*3, [0.5]*3)
])

# Class labels (must match training dataset)
class_names = train_dataset.classes  # ['Alluvial', 'Black', 'Clay', 'Red']

# Function to predict soil type
def predict_soil(image_path, model, transform, class_names):
    image = Image.open(image_path).convert("RGB")
    image = transform(image).unsqueeze(0).to(device)  # Add batch dimension

    with torch.no_grad():
        outputs = model(image)
        _, predicted = torch.max(outputs, 1)
        predicted_class = class_names[predicted.item()]
    return predicted_class

# üî∏ User provides the image path
user_image_path = input("Enter the full path to the soil image: ").strip()

# ‚úÖ Check if path is valid and predict
if os.path.isfile(user_image_path):
    predicted_soil = predict_soil(user_image_path, model_custom, transform, class_names)
    print(f"Predicted Soil Type: {predicted_soil}")
else:
    print("‚ùå Invalid image path. Please check and try again.")